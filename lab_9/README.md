# Лабораторная работа 9.

## Цели работы

1. Настройка eBGP.

## Задачи

1. Настроить eBGP между офисом Москва и двумя провайдерами - Киторн и Ламас.
2. Настроить eBGP между провайдерами Киторн и Ламас.
3. Настроить eBGP между Ламас и Триада.
4. Настроить eBGP между офисом С.-Петербург и провайдером Триада.
5. Организовать IP доступность между офисами Москва и С.-Петербург.
6. Настроить отслеживание линка через технологию IP SLA.

## План работ

1. Настроить BGP на маршрутизаторах площадок Киторн, Ламас, Триада, С.-Петербург (R18), Москва (R14-R15).
2. Организация доступности между офисами Москва и С.-Петербург. 
    1. Настройка NAT на площадке С.-Петербург.
    2. Настройка NAT на площадке Москва.
    3. Настройка VPN между площадками Москва и С.-Петербург.
    4. Настройка связности между площадками.
3. Настроить IP SLA.

--- 
 
**Рис. 1. - Общая схема сети.**

![Схема сети](l9.png)

---

**Табл. 1 - Список AS.**

| ASN | Площадка |
| :--: | :--: |
| 101 | Киторн |
| 301 | Ламас |
| 520 | Триада |
| 1001 | Москва |
| 2042 | С.-Петербург |

---

**Табл. 2 - Список соседей.**

| Имя маршрутизатора | ASN **маршрутизатора**/соседа | Адрес соседа |
| -- | -- | -- |
| **R14** | **1001** | |
| | 101 | 10.255.0.47 |
| | 1001 | 10.96.1.253 |
| | | |
| **R15** | **1001** | |
| | 301 | 10.255.0.13 |
| | 1001 | 10.96.1.254 |
| | | |
| **R18** | **2042** | |
| | 520 | 10.255.0.21 |
| | 520 | 10.255.0.23 |
| | | |
| **R21** | **301** | |
| | 101 | 10.255.0.25 |
| | 520 | 10.255.0.27 |
| | 1001 | 10.255.0.12 |
| | | |
| **R22** | **101** | |
| | 301 | 10.255.0.24 |
| | 520 | 10.255.0.29 |
| | 1001 | 10.255.0.46 |
| | | |
| **R23** | **520** | |
| | 101 | 10.255.0.28 |
| | 520 | 10.96.7.251 |
| | 520 | 10.96.7.252 |
| | 520 | 10.96.7.253 |
| | | |
| **R24** | **520** | |
| | 301 | 10.255.0.26 |
| | 520 | 10.96.7.251 |
| | 520 | 10.96.7.252 |
| | 520 | 10.96.7.254 |
| | 2042 | 10.255.0.20 |
| | | |
| **R25** | **520** | |
| | 520 | 10.96.7.251 |
| | 520 | 10.96.7.253 |
| | 520 | 10.96.7.254 |
| | | |
| **R26** | **520** | |
| | 520 | 10.96.7.252 |
| | 520 | 10.96.7.253 |
| | 520 | 10.96.7.254 |
| | 2042 | 10.255.0.22 |

---

**Табл. 3 - Перечень соединений VPN между площадками Москва и С.-Петербург**

| Л. устройство | Л. интерфейс | Л. ВНШ адрес | Л. ВНТ адрес | П. устройство | П. интерфейс | П. ВНШ адрес | П. ВНТ адрес |
| -- | -- | -- | -- | -- | -- | -- | -- |
| R14 | Ethernet0/2 | 10.255.0.46/31 | 10.255.0.52/31 | R18 | Ethernet0/2 | 10.255.0.20/31 | 10.255.0.53/31 |
| R15 | Ethernet0/2 | 10.255.0.12/31 | 10.255.0.54/31 | R18 | Ethernet0/3 | 10.255.0.22/31 | 10.255.0.55/31 |
| R18 | Ethernet0/2 | 10.255.0.20/31 | 10.255.0.53/31 | R14 | Ethernet0/2 | 10.255.0.46/31 | 10.255.0.52/31 |
| R18 | Ethernet0/3 | 10.255.0.22/31 | 10.255.0.55/31 | R15 | Ethernet0/2 | 10.255.0.12/31 | 10.255.0.54/31 |

> Для удобства последующей настройки в данной таблице присутствует избыточность в виде зеркального отображения соединений.

---

Все конфигурационные файлы расположены в каталоге [cfg](./cfg/).

---

! Изменения в топологии в последующих работах:

1. [Лабораторная работа 10](../lab_10). На площадке Триада iBGP переделан под route reflector.

2. [Лабораторная работа 12](../lab_12). Исправлена работа NAT на R14 (и в принципе внесены правки в NAT R18/R14-15)

---

! Изменения в топологии по отношению к предыдущим работам:

1. Исправление конфигурации OSPF пл. Москва: 

    1. Включен пассивный режим по умолчанию на всех интерфейсах маршрутизаторов R12-R15:R19-R20 (как для IPv4,  так и для IPv6).
    2. Вручную включены только порты в сторону других маршрутизаторов данной площадки (В соответствии с [Табл. 2 Л.Р. 6](../lab_6) и [Табл. 2 Л.Р. 7](../lab_7)).

    3. Интерфейсы R14:E0/2 и R15:E0/2 выведены из area 0 OSPF IPv4 и IPv6.
    4. Добавлено соединение R14:E1/0 - R15:E1/0 с адресами, указанными в Табл. 4.
    5. R14:E1/0 и R15:E1/0 включены в area 0 OSPF IPv4 и IPv6.
    6. На R12 и R13 явно указана сеть 10.1.0.0/16 для зоны 10 OSPF.
    
    **Табл. 4 - Информация о новом соединении.**

    | Маршрутизатор | Порт | Адрес |
    | :--: | :--: | :-- |
    | R14 | Ethernet1/0 | 10.255.0.50/31 |
    | | | 2020::1:0:1:401/120 |
    | | | fe80::1:14:4 |
    | R15 | Ethernet1/0 | 10.255.0.51/31 |
    | | | 2020::1:0:2:401/120 |
    | | | fe80::1:15:4 |

    Данное изменение вызвано тем, что R15 внезапно начал видеть default GW (посредством OSPF) в районе R12-R13, также дальнейший разбор проблемы показал, что на самом деле зоны backbone не присутствовало на площадке. 

2. На R14 и R18 убраны оставшиеся статические маршруты по умолчанию.
3. На площадке Ламас сконфигурирован и запущен OSPF с редистрибьюцией сети 10.96.7.0/24 в area 0. В качестве router-id выступают адреса loopback интерфейсов.
4. На площадке Москва в OSPF добавлена сеть 10.96.1.0/24 в area 0 для работы iBGP через L0 адреса.
5. На площадке С.-Петербург на R18 в EIGRP добавлена суммаризация маршрутов до `0.0.0.0/0` и размещена на интерфейсах E0/0-1 (Иначе R17 и R16 не имели default-gw).

---

## Выполнение

### Настройка BGP на маршрутизаторах.

1. На каждом маршрутизаторе площадок (см. Табл. 2) настраиваем BGP (команды выполняются в режиме конфигурации):

        router bgp <ASN>
          neighbor <IP_neigh> remote-as <ASN_neigh>
    
    Где:

    * `<ASN>` - номер AS маршрутизатора.
    * `<IP_neigh>` - IP адрес соседа.
    * `<ASN_neigh>` - номер AS соседа.
    
    Указанные параметры также перечислены в Табл. 2 для каждого маршрутизатора. Если сосед находится в той же AS, указываем вместо IP адреса интерфейса, IP адрес loopback, а также дополнительно прописываем команду `neighbor <IP_neigh> update-source loopback0`.
    
    Для маршрутизаторов, кроме R14-R15, R18 также дополнительно введена команда `redistribute connected`.
    
2. Проверяем командой `show bgp ipv4 unicast summary` наличие соседей (вывод на примере R24):

        R24#sh bgp ipv4 un sum
        BGP router identifier 10.96.7.253, local AS number 520
        BGP table version is 20, main routing table version 20
        1 network entries using 148 bytes of memory
        2 path entries using 128 bytes of memory
        2/1 BGP path/bestpath attribute entries using 272 bytes of memory
        1 BGP AS-PATH entries using 24 bytes of memory
        0 BGP route-map cache entries using 0 bytes of memory
        0 BGP filter-list cache entries using 0 bytes of memory
        BGP using 572 total bytes of memory
        BGP activity 9/8 prefixes, 20/18 paths, scan interval 60 secs

        Neighbor        V           AS MsgRcvd MsgSent   TblVer  InQ OutQ Up/Down  State/PfxRcd
        10.255.0.20     4         2042      74      75       20    0    0 01:00:35        1
        10.255.0.26     4          301      76      80       20    0    0 01:05:16        0
        10.255.0.30     4          520      79      84       20    0    0 01:08:45        0
        10.255.0.35     4          520      78      76       20    0    0 01:02:58        1
    
### Обеспечение связности сетей площадок Москва и С.-Петербург.

#### Настройка NAT на площадке C.-Петербург.

Настройка проводится на R18. Т.к. у нас присутствует всего два адреса во вне (до R24 и R26), а количество клиентов может быть гораздо большим исходя из выделенных подсетей), используем PAT.

1. Создаем access-list на клиентские подсети.

        ip access-list extended ADDR_TO_NAT
          10 permit ip 10.2.0.0 0.0.255.255 any
          40 deny ip any any
          exit

2. Создаем 2 route-map (до R24 и R26 соответственно).

        route-map NAT_TO_R24
          match ip address ADDR_TO_NAT
          match interface Ethernet0/2
          exit
          
        route-map NAT_TO_R26
          match ip address ADDR_TO_NAT
          match interface Ethernet0/3
          exit

3. Создаем трансляцию на интерфейсах Ethernet0/2-3.

        ip nat inside source route-map NAT_TO_R24 interface Ethernet0/2 overload
        ip nat inside source route-map NAT_TO_R26 interface Ethernet0/3 overload        

4. Маркируем интерфейсы.
        
        interface range Ethernet0/2-3
          ip nat outside
          exit
        
        interface range Ethernet0/0-1
          ip nat inside
          exit
          
5. Командой `trace 10.255.0.33` (R25) с VPC8 проверяем работоспособность NAT.

        VPCS> trace 10.255.0.33
        trace to 10.255.0.33, 8 hops max, press Ctrl+C to stop
        1   10.2.20.1   1.256 ms  1.476 ms  0.985 ms
        2   10.255.0.19   7.629 ms  1.493 ms  1.758 ms
        3   10.255.0.23   2.038 ms  1.555 ms  1.603 ms
        4   *10.255.0.36   1.741 ms (ICMP type:3, code:3, Destination port unreachable)  *

#### Настройка NAT на площадке Москва.

1. Настройка аналогична С.-Петербург, за исключением смены переменных. В access-list добавляется сеть `10.1.0.0/16`. И на R14 и на R15 в качестве outside интерфейса указывается Ethernet0/2, а inside - Ethernet0/0-1,3; Ethernet1/0.

2. Проводим аналогичную трассировку с VPC1.

        VPCS> trace 10.255.0.33
        trace to 10.255.0.33, 8 hops max, press Ctrl+C to stop
        1   10.1.10.1   1.859 ms  0.760 ms  0.846 ms
        2   10.255.0.1   1.689 ms  1.444 ms  1.263 ms
        3   10.255.0.47   1.945 ms  1.362 ms  1.283 ms
        4   10.255.0.29   2.121 ms  1.065 ms  1.529 ms
        5   *10.255.0.33   1.884 ms (ICMP type:3, code:3, Destination port unreachable)  *

#### Настройка VPN между площадками Москва и С.-Петербург.

В данном пункте обеспечиваем связь между площадками посредством IPSec. Настраиваем два канала, в соответствии с Табл. 3.

1. Указываем параметры шифрования и ключ для каждого адреса отдельно.
    
        crypto isakmp policy 1
          encr aes 256
          hash sha256
          authentication pre-share
          group 14
        
        crypto isakmp key <KEY> address <REMOTE_IP>
        
        crypto ipsec transform-set <TRANSFORM_SET_NAME> ah-sha256-hmac esp-aes 
          mode tunnel
          exit

        crypto ipsec profile <PROFILE_NAME>
          set transform-set <TRANSFORM_SET_NAME>
          exit
            
    Где:
    
    * `KEY` - ключ для аутентификации.
    * `REMOTE_IP` - адрес удаленного хоста (по отношению к маршрутизатору, на котором выполняется конфигурация, в Табл. 3 указан как параметр `П. ВНШ. адрес`.).
    * `TRANSFORM_SET_NAME` - наименование набора преобразований.
    * `PROFILE_NAME` - наименование ipsec профиля.
    

2. Создаем новый интерфейс с типом `Tunnel`:
    
        interface Tunnel0
          ip address <IP_ADDR> <MASK>
          keepalive 10 3
          bandwith 10000
          tunnel source <OUT_IFACE>
          tunnel mode ipsec ipv4
          tunnel destination <REMOTE_IN_ADDR>
          tunnel protection ipsec profile <PROFILE_NAME>
          exit
            
    Где, согласно Табл. 3 относительно каждого настраиваемого соединения:
    
    * `IP_ADDR` - `Л. ВНТ адрес`
    * `MASK` - маска из `Л. ВНТ адрес`
    * `OUT_IFACE` - `Л. интерфейс`
    * `REMOTE_IN_ADDR` - `П. ВНШ адрес`
    * `PROFILE_NAME` - наименование ipsec профиля.
    
    В данном случае на R18 создаются интерфейсы Tunnel0 и Tunnel1. Дополнительно, явным образом задаем пропускную способность выше стандартной (10 мбит/с).
    
#### Настройка связности между площадками.

Для обеспечения связности также используем BGP и по два access-list на каждом устройстве. Логика заключается в том, чтобы отфильтровывать 10.1.0.0/16 и 10.2.0.0/16 через `GENERAL-restrict` в сторону внешних соединений, а в сторону `AS<NUM>-restrict` отдавать только одну из этих сетей (соотвественно из 1001 будем отдавать 10.1.0.0/16, а из 2042 - 10.2.0.0/16)

1. На R14-15, R18 создаем общий access-list, исключающий анонс внутренних сетей.
        
        ip access-list GENERAL-restrict
          10 deny ip 10.1.0.0 0.0.255.255 any
          20 deny ip 10.2.0.0 0.0.255.255 any
          30 permit any any
          
2. На R18 создаем выходной ACL.

        ip access-list AS1001-restrict
          10 permit ip 10.2.0.0 0.0.255.255 any
          20 ip deny any any
          exit

3. Настраиваем BGP на R18, указывая на внешние соединения `GENERAL-restrict`, добавляем по внутреннему адресу соседей из AS1001, также добавляя выходную политику.

        router bgp 2042
        
          neighbor 10.255.0.21 distribute-list GENERAL-restrict out
          neighbor 10.255.0.23 distribute-list GENERAL-restrict out
        
          neighbor 10.255.0.52 remote-as 1001
          neighbor 10.255.0.52 distribute-list AS1001-restrict out
          neighbor 10.255.0.54 remote-as 1001
          neighbor 10.255.0.54 distribute-list AS1001-restrict out

4. Анонсируем саму сеть.

        network 10.2.0.0 mask 255.255.0.0
        
5. Аналогичные действия выполняем на R14-15.

        ip access-list AS2042-restrict
          10 permit ip 10.1.0.0 0.0.255.255 any
          20 ip deny any any
          exit
        
        router bgp 1001
          neighbor <EXT_NEIGHBOR_IP> distribute-list GENERAL-restrict outside
          neighbor <INT_NEIGHBOR_IP> remote-as 2042
          neighbor <INT_NEIGHBOR_IP> distribute-list AS2042-restrict
          
    Где:
    
    * `EXT_NEIGHBOR_IP` - внешний сосед маршрутизатора (10.255.0.47 для R14, 10.255.0.13 для R15)
    * `INT_NEIGHBOR_IP` - адрес R18, доступный через IPSec (10.255.0.53 для R14, 10.255.0.55 для R15)

6. Дополнительно на R14-15 прописываем фиктивный маршрут, чтобы BGP мог его анонсировать: `ip route 10.1.0.0 255.255.0.0 Null0`.
    
7. Проверяем на стороннем маршрутизаторе наличие внутренних сетей (на примере R23):

        R23>sh ip ro bgp
        
        // -- //
        
        Gateway of last resort is not set

        10.0.0.0/8 is variably subnetted, 24 subnets, 2 masks
        B        10.96.3.254/32 [20/0] via 10.255.0.28, 00:31:25
        B        10.96.4.254/32 [200/0] via 10.255.0.26, 00:31:20
        B        10.255.0.12/31 [200/0] via 10.255.0.26, 00:31:20
        B        10.255.0.20/31 [200/0] via 10.96.7.253, 00:31:25
        B        10.255.0.22/31 [200/0] via 10.96.7.251, 00:31:25
        B        10.255.0.24/31 [20/0] via 10.255.0.28, 00:31:25
        B        10.255.0.26/31 [200/0] via 10.96.7.253, 00:31:25
        B        10.255.0.38/31 [200/0] via 10.96.7.252, 00:31:25
        B        10.255.0.40/31 [200/0] via 10.96.7.252, 00:31:25
        B        10.255.0.42/31 [200/0] via 10.96.7.251, 00:31:25
        B        10.255.0.44/31 [200/0] via 10.96.7.251, 00:31:25
        B        10.255.0.46/31 [20/0] via 10.255.0.28, 00:31:25
        
8. Проверяем трассировкой наличие доступа:

    1. С.-Петербург - Москва
    
            VPCS> trace 10.1.10.11 
            trace to 10.1.10.11, 8 hops max, press Ctrl+C to stop
            1   10.2.20.1   1.469 ms  0.352 ms  0.577 ms
            2   10.255.0.19   3.534 ms  0.944 ms  0.654 ms
            3   10.255.0.52   4.680 ms  2.393 ms  1.945 ms
            4   10.255.0.4   4.242 ms  2.007 ms  2.318 ms
            5   *10.1.10.11   3.281 ms (ICMP type:3, code:3, Destination port unreachable)
            
    2. Москва - С.-Петербург

            VPCS> trace 10.2.20.11
            trace to 10.2.20.11, 8 hops max, press Ctrl+C to stop
            1   10.1.11.1   2.539 ms  1.175 ms  1.095 ms
            2   10.255.0.5   2.125 ms  1.116 ms  0.948 ms
            3   10.255.0.53   4.574 ms  2.530 ms  3.168 ms
            4   10.255.0.14   5.882 ms  3.558 ms  7.844 ms
            5   *10.2.20.11   4.179 ms (ICMP type:3, code:3, Destination port unreachable)

    Из чего делаем вывод что связность между площадками присутствует, но об этой связности никто кроме этих площадок не знает.
          
### Настройка IP SLA.

> Условие `match track` при использовании внутри `neighbor <IP> fall-over` не поддерживается в образах до версии 15.7 включительно (возможно выше - тоже, но тестирование выше указанной версии не проводилось). Поэтому данный раздел представлен как информативный, сама конфигурация на стенде не выполнялась.

> Также, вместо ip sla имеет смысл использовать BFD (который, к сожалению, также не поддерживается внутри виртуализации).

1. Создаём prefix-list:

        ip prefix-list <LIST_NAME> seq 5 permit <NEIGHBOR_IP>/32

    Где `LIST_NAME` - наименование, а `NEIGHBOR_IP` - адрес соседа.

2. Создаем непосредственно IP SLA, в котором мы пингуем соседа каждые 5 секунд:

        ip sla <SLA_NUM>
            icmp-echo <CHECK_IP> source-ip <IFACE_IP>
            frequency 5
    
    Где `SLA_NUM` - номер объекта,`CHECK_IP` - ip-адрес, доступность которого проверяем при помощи IP SLA, а `IFACE_IP` - адрес интерфейса, с которого проводится проверка.

3. Запускаем созданный IP SLA:

        ip sla schedule <SLA_NUM> life forever start-time now

4. Запускаем трек с номером `TRACK_NUM`, который будет ждать отсутствие ответа 2 раза подряд:

        track <TRACK_NUM> ip sla <SLA_NUM> reachability
            delay down 10
            
5. Далее создаём route-map, в котором ищем соответствие ранее созданному префикс листу:

        route-map <ROUTEMAP_NAME> permit 10
            match track <TRACK_NUM>

    Где `ROUTEMAP_NAME` - наименование route map.
        
6. В настройке BGP указываем для выбранного соседа параметр `fall-over` и ссылку на созданный route-map:

        router bgp <ASN>
            neighbor <NEIGHBOR_IP> fall-over route-map <ROUTEMAP_NAME>
